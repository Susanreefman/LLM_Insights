{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc4ac89-452b-4d23-a166-24a0ce8e6e4e",
   "metadata": {},
   "source": [
    "# Summarization with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa5344a4-8f31-45ba-be2e-d1c663c73eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "import pandas as pd\n",
    "\n",
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# pytorch build model\n",
    "import torch\n",
    "import collections \n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import math\n",
    "from time import perf_counter\n",
    "\n",
    "# evaluation method\n",
    "from evaluate import load\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02231fb2-8a8f-4315-9769-90715787d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/vboxuser/Documents/data_old.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c050f8a-b623-4728-9c69-fd4e8f07755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = tts(data['Text'],data['Summary'],test_size=0.1, shuffle=True, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e2d2dbb-1c19-46f3-9bbd-d76fa3913fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function \n",
    "def tokenize(lines, token='word'):\n",
    "    \"\"\"Make from sentence a list like [\"Make\", \"from\", \"sentence\"]\"\"\"\n",
    "    assert token in ('word', 'char'), 'Unknown token type: ' + token\n",
    "    return [line.split() if token == 'word' else list(line) for line in lines]\n",
    "\n",
    "# padding function\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "def build_array_sum(lines, vocab, num_steps):\n",
    "    \"\"\"function to add eos and padding and also determine valid length of each data sample\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    # Add end of sentence\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    #Create tensor with padding\n",
    "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    #Make all lines equal length by padding\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len\n",
    "\n",
    "# create the tensor dataset object \n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1562a07-57a4-4718-a92b-b2cadbdcf83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_qkv(X, num_heads):\n",
    "    # Function to transpose the linearly transformed query key and values \n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    # For output formatting \n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "    \n",
    "\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    # Here masking is used so that irrelevant padding tokens are not considered while calculations\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32)[None, :] < valid_len[:, None]    #device=X.device\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "    \n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    # the irrelevant tokens are given a very small negative value which gets ignored in the subsequent calculations\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1) \n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aabe0e70-0a28-41ff-8e05-439ca6183b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(i=0):\n",
    "    if torch.cuda.device_count() >= i+1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def grad_clipping(net, theta):\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e7703-8a0d-45d9-80ec-3442930a5ae2",
   "metadata": {},
   "source": [
    "### Vocab\n",
    "#### Building vocabulary on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "496e2581-3b90-42c2-914a-214a33907f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vocabulary class \n",
    "class Vocab:\n",
    "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
    "        # Flatten a 2D list if needed\n",
    "        if tokens and isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        # Count token frequencies\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The list of unique tokens\n",
    "        self.idx_to_token = list(sorted(set(['<unk>'] + reserved_tokens + [\n",
    "            token for token, freq in self.token_freqs if freq >= min_freq])))\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if hasattr(indices, '__len__') and len(indices) > 1:\n",
    "            return [self.idx_to_token[int(index)] for index in indices]\n",
    "        return self.idx_to_token[indices]\n",
    "\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return self.token_to_idx['<unk>']\n",
    "    \n",
    "    def print_variable(self):\n",
    "        print(\"Variable idx_to_token:\", self.idx_to_token)\n",
    "        print(\"Variable idx_to_token:\", self.token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f85a4-f753-49be-b12c-2505bb36eaeb",
   "metadata": {},
   "source": [
    "### Multi Head Attention\n",
    "\n",
    "#### class EncoderBlock & Decoderblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ab7c4a6-5979-46c4-a68e-50dafd5fae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main class \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.w_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.w_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.w_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.w_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "        \n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries = transpose_qkv(self.w_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.w_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.w_v(values), self.num_heads)\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, repeats = self.num_heads, dim=0)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        \n",
    "        return self.w_o(output_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c952be-35f4-4a97-bbc3-d4752d10ffae",
   "metadata": {},
   "source": [
    "### Dot Product Attention \n",
    "A simplified form of attention that calculates the similar\\ity between query and key vectors by taking their dot product.\n",
    "#### (class MultiHeadAttention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a055dc27-9f1f-4a3b-a6ae-ab6388c4a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    # The dot product attention scoring function \n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2))/math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        \n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3a1a4-03b9-47f3-a3c0-e0a144460311",
   "metadata": {},
   "source": [
    "### Positionwise feedforward network \n",
    "#### (class Encoder & Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49f87d9c-b3f3-41a8-b929-cc9244d9e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_output, **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_output)\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e067969-568b-48cc-bc7e-c0100313fe99",
   "metadata": {},
   "source": [
    "### Postional Encoding\n",
    "Provide positional information to the model, positional encoding is added to the input embeddings to convey information about the order of tokens in the sequence.\n",
    "#### (class TransformerEncoding TransformerDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f274209-2d26-4d68-88a1-01ce13b17af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1)/torch.pow(10000,torch.arange(0, num_hiddens,2, dtype=torch.float32)/num_hiddens)\n",
    "        self.P[:,:, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098851d1-76c8-419e-a13c-7f3909bb77d2",
   "metadata": {},
   "source": [
    "### EncoderBlock & Transformer Encoder\n",
    "#### Initializing encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd372d87-5aab-41dd-91d6-64712d3519bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the block structure within \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, \n",
    "                 ffn_num_hiddens, num_heads, dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(key_size, query_size, value_size, num_hiddens,num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        \n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "\n",
    "# the main encoder class\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),EncoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias))\n",
    "    \n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        X = self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None]*len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d8ed33-958b-49fc-af9c-a925473036cb",
   "metadata": {},
   "source": [
    "### DecoderBlock & TransformerDecoder\n",
    "#### Initializing decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62a49fad-ff86-43cd-a6c9-c63cf2fc3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                 ffn_num_input, ffn_num_hiddens, num_heads, dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "        \n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        if state[2][self.i] is None: # true when training the model\n",
    "            key_values = X\n",
    "        else:                        # while decoding state[2][self.i] is decoded output of the ith block till the present time-step\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            dec_valid_lens = torch.arange(1, num_steps+1, device = X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "\n",
    "# The main decoder class \n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i), \n",
    "                                DecoderBlock(key_size, query_size, value_size,\n",
    "                                             num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, i))\n",
    "            self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "    \n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None]*self.num_layers]\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None]*len(self.blks) for _ in range(2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n",
    "            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "    \n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5d10d-1afe-4165-a929-8ffcf1154ea4",
   "metadata": {},
   "source": [
    "### AddNorm\n",
    "encapsulates the common pattern of combining element-wise addition with layer normalization and dropout, which is widely used in transformer architectures to facilitate effective training and improved performance.\n",
    "#### class EncoderBlock & DecoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ce5127b-0160-4a21-8764-5090cb3e5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"The residual connection followed by layer normalization.\"\"\"\n",
    "    def __init__(self, norm_shape, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(norm_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221780c-8528-48fc-b972-d82d02701ed1",
   "metadata": {},
   "source": [
    "### Accumulator\n",
    "\n",
    "#### Used in training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0899de4b-9188-493a-8c18-ae3f02a0d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438929b-a67b-4281-8ebd-c194664ed9f9",
   "metadata": {},
   "source": [
    "### Masked Softmax CE Loss\n",
    "#### Loss function in training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81fb0021-4ed1-437c-ae95-33f0800675ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5775cb-71a6-429b-ba2f-6b892d253951",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "#### Initialize full model (encoder+decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3771a77f-39a2-45fc-8047-a5196ea95fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_all_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_all_outputs, *args)\n",
    "        # Return decoder output only\n",
    "        return self.decoder(dec_X, dec_state)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2051dd",
   "metadata": {},
   "source": [
    "Train and predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df86505a-9013-408e-bb0e-2584a291e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):    \n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            train_losses.append(l)\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if epoch%5==0:\n",
    "            print(f\"Done with epoch number: {epoch}\") # optional step\n",
    "    print(f'loss {metric[0] / metric[1]:.3f} on {str(device)}')\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8127f64-afe3-43c3-879a-7c5b8a9383f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,device, save_attention_weights=False):\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    src_tokens = [x for x in src_tokens if str(x).isdigit()]\n",
    "    # Unsqueeze adds another dimension that works as the the batch axis here\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis to the decoder now\n",
    "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y = net.decoder(dec_X, dec_state)[0]\n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "            # Once the end-of-sequence token is predicted, the generation of the output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "                break\n",
    "        output_seq.append(pred)\n",
    "    if len(output_seq)<2:\n",
    "\n",
    "        if len(output_seq)==1: \n",
    "            return ''.join(tgt_vocab.to_tokens(output_seq[0])), attention_weight_seq   \n",
    "        else:\n",
    "\n",
    "            return \"No output!\", attention_weight_seq\n",
    "    else:\n",
    "        return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880123ee-c29e-41de-ba5e-89bffc0d7c38",
   "metadata": {},
   "source": [
    "### Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e355b7f-c68c-4c53-836f-f4aaa7cc8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with epoch number: 0\n",
      "Done with epoch number: 5\n",
      "Done with epoch number: 10\n",
      "Done with epoch number: 15\n",
      "Done with epoch number: 20\n",
      "Done with epoch number: 25\n",
      "Done with epoch number: 30\n",
      "Done with epoch number: 35\n",
      "Done with epoch number: 40\n",
      "Done with epoch number: 45\n",
      "loss 0.001 on cpu\n",
      "Verstreken tijd: 0.3 minuten.\n",
      "SAMPLE : Soil water is now less than the refill point. Plant water stress can occur if refill status persists. At least 8.67 mm of additional soil water is needed to achieve optimal soil water status, and there is currently storage capacity for up to 25.09 mm of additional irrigation and rainwater. In some crops, intentional crop drying practices are sometimes needed. Dry soil conditions may be desirable in those certain situations. The circumstances are favorable for a well-protected crop.\n",
      "ACTUAL : Soil water is below refill point, risking plant water stress. An additional 8.67 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 25.09 mm. The circumstances are favorable for a well protected crop.\n",
      "PREDICTED : Soil water is below refill point, risking plant water stress. An additional 7.89 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 27.89 mm. The circumstances are favorable for a well protected crop.\n",
      "\n",
      "SAMPLE : Soil water is now less than the refill point. Plant water stress can occur if refill status persists. At least 15.78 mm of additional soil water is needed to achieve optimal soil water status, and there is currently storage capacity for up to 35.91 mm of additional irrigation and rainwater. In some crops, intentional crop drying practices are sometimes needed. Dry soil conditions may be desirable in those certain situations. The circumstances are favorable for a well-protected crop.\n",
      "ACTUAL : Soil water is below refill point, risking plant water stress. An additional 15.78 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 35.91 mm. The circumstances are favorable for a well protected crop.\n",
      "PREDICTED : Soil water is below refill point, risking plant water stress. An additional 7.89 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 27.89 mm. The circumstances are favorable for a well protected crop.\n",
      "\n",
      "SAMPLE : Soil water is now less than the refill point. Plant water stress can occur if refill status persists. At least 7.54 mm of additional soil water is needed to achieve optimal soil water status, and there is currently storage capacity for up to 30.12 mm of additional irrigation and rainwater. In some crops, intentional crop drying practices are sometimes needed. Dry soil conditions may be desirable in those certain situations. The circumstances are favorable for a well-protected crop.\n",
      "ACTUAL : Soil water is below refill point, risking plant water stress. An additional 7.54 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 30.12 mm. The circumstances are favorable for a well protected crop.\n",
      "PREDICTED : Soil water is below refill point, risking plant water stress. An additional 7.89 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 27.89 mm. The circumstances are favorable for a well protected crop.\n",
      "\n",
      "SAMPLE : Soil water is now less than the refill point. Plant water stress can occur if refill status persists. At least 13.02 mm of additional soil water is needed to achieve optimal soil water status, and there is currently storage capacity for up to 48.71 mm of additional irrigation and rainwater. In some crops, intentional crop drying practices are sometimes needed. Dry soil conditions may be desirable in those certain situations. The circumstances are favorable for a well-protected crop.\n",
      "ACTUAL : Soil water is below refill point, risking plant water stress. An additional 13.02 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 48.71 mm. The circumstances are favorable for a well protected crop.\n",
      "PREDICTED : Soil water is below refill point, risking plant water stress. An additional 7.89 mm of water is needed to reach optimal soil moisture levels, with capacity for up to 27.89 mm. The circumstances are favorable for a well protected crop.\n",
      "\n",
      "SAMPLE : Current soil water status is nearing the full point. Plant damage and cost inefficiency can occur if the full point is exceeded. Currently only 4.08 mm of storage capacity remain for additional irrigation and rain. An additional irrigation at this time could add input costs with zero or negative agronomic benefit. In situations with low root zone water storage capacity, it can be effective to apply frequent smaller irrigations\n",
      "ACTUAL : The soil water status is nearing the full point, risking plant damage and cost inefficiency if exceeded. Only 4.08 mm of storage capacity remain.\n",
      "PREDICTED : Soil water is nearing full capacity, risking plant damage and cost inefficiency if exceeded. Only 1.45 mm of storage capacity remains, and additional irrigation now could incur costs with minimal agronomic benefit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "src_tokens = tokenize(x_train)\n",
    "tgt_tokens = tokenize(y_train)\n",
    "\n",
    "# build vocabulary on dataset\n",
    "src_vocab = Vocab(src_tokens, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocab(tgt_tokens, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "max_len_text=150\n",
    "max_len_summary=50\n",
    "\n",
    "src_array, src_valid_len = build_array_sum(src_tokens, src_vocab, max_len_text)\n",
    "tgt_array, tgt_valid_len = build_array_sum(tgt_tokens, tgt_vocab, max_len_summary)\n",
    "data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "\n",
    "#Create tensor dataset object\n",
    "batch_size = 16\n",
    "data_iter = load_array(data_arrays, batch_size)\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# Initialize model\n",
    "num_hiddens, num_layers, dropout, num_steps = 32, 2, 0.1, 100\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "encoder = TransformerEncoder(len(src_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,num_layers, dropout)\n",
    "decoder = TransformerDecoder(len(tgt_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,num_layers, dropout)\n",
    "\n",
    "net = Transformer(encoder, decoder)\n",
    "\n",
    "\n",
    "starttime = perf_counter()\n",
    "lr = 0.005\n",
    "num_epochs = 50\n",
    "train_losses = train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device)\n",
    "print(f'Verstreken tijd: {(perf_counter() - starttime) / 60.0:.1f} minuten.')\n",
    "\n",
    "sample = x_test[:10]\n",
    "actual = y_test[:10]\n",
    "predictions = []\n",
    "for s, a in zip(sample, actual):\n",
    "    pred_sum, _ = predict_seq2seq(net, s, src_vocab, tgt_vocab, max_len_summary, device)\n",
    "    predictions.append(pred_sum)\n",
    "    print(\"SAMPLE : {}\".format(s))\n",
    "    print(\"ACTUAL : {}\".format(a))\n",
    "    print(\"PREDICTED : {}\".format(pred_sum))\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "feade855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.8527093596059114, 'rouge2': 0.7806620209059234, 'rougeL': 0.8527093596059114, 'rougeLsum': 0.8527093596059114}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "y = actual.tolist()\n",
    "\n",
    "ref = []\n",
    "for i in y:\n",
    "    ref.append([i])\n",
    "\n",
    "results = rouge.compute(predictions=predictions, references=ref)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "880b8f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pandas\n",
      "Version: 2.1.4\n",
      "Summary: Powerful data structures for data analysis, time series, and statistics\n",
      "Home-page: https://pandas.pydata.org\n",
      "Author: \n",
      "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
      "License: BSD 3-Clause License\n",
      "\n",
      "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
      "All rights reserved.\n",
      "\n",
      "Copyright (c) 2011-2023, Open source contributors.\n",
      "\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "modification, are permitted provided that the following conditions are met:\n",
      "\n",
      "* Redistributions of source code must retain the above copyright notice, this\n",
      "  list of conditions and the following disclaimer.\n",
      "\n",
      "* Redistributions in binary form must reproduce the above copyright notice,\n",
      "  this list of conditions and the following disclaimer in the documentation\n",
      "  and/or other materials provided with the distribution.\n",
      "\n",
      "* Neither the name of the copyright holder nor the names of its\n",
      "  contributors may be used to endorse or promote products derived from\n",
      "  this software without specific prior written permission.\n",
      "\n",
      "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "Location: /home/vboxuser/anaconda3/lib/python3.11/site-packages\n",
      "Requires: numpy, python-dateutil, pytz, tzdata\n",
      "Required-by: altair, bokeh, datasets, datashader, evaluate, holoviews, hvplot, panel, seaborn, statsmodels, streamlit, xarray\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79e4afd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'version' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[68], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m version(sklearn\u001B[38;5;241m.\u001B[39mmodel_selection)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'version' is not defined"
     ]
    }
   ],
   "source": [
    "version(sklearn.model_selection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f46739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\r\n",
      "accelerate==0.29.3\r\n",
      "aext_assistant @ file:///croot/aext-assistant_1698112894723/work\r\n",
      "aext_assistant_server @ file:///croot/aext-assistant-server_1698104604055/work/backend_lib/assistant\r\n",
      "aext_core @ file:///croot/aext-core_1698107546104/work\r\n",
      "aext_core_server @ file:///croot/aext-core-server_1698098080063/work/backend_lib/core\r\n",
      "aext_shared @ file:///croot/aext-shared_1698068305627/work/backend_lib/shared\r\n",
      "aiobotocore @ file:///croot/aiobotocore_1701291493089/work\r\n",
      "aiofiles @ file:///croot/aiofiles_1683773582346/work\r\n",
      "aiohttp @ file:///croot/aiohttp_1707342283163/work\r\n",
      "aioitertools @ file:///tmp/build/80754af9/aioitertools_1607109665762/work\r\n",
      "aiosignal @ file:///tmp/build/80754af9/aiosignal_1637843061372/work\r\n",
      "aiosqlite @ file:///croot/aiosqlite_1683773899903/work\r\n",
      "alabaster @ file:///home/ktietz/src/ci/alabaster_1611921544520/work\r\n",
      "altair @ file:///croot/altair_1687526041770/work\r\n",
      "anaconda-anon-usage @ file:///croot/anaconda-anon-usage_1697038922993/work\r\n",
      "anaconda-catalogs @ file:///croot/anaconda-catalogs_1685727283692/work\r\n",
      "anaconda-client @ file:///croot/anaconda-client_1708640631824/work\r\n",
      "anaconda-cloud-auth @ file:///croot/anaconda-cloud-auth_1713991386423/work\r\n",
      "anaconda-navigator @ file:///croot/anaconda-navigator_1713464016024/work\r\n",
      "anaconda-project @ file:///work/ci_py311/anaconda-project_1676846728333/work\r\n",
      "anyio @ file:///croot/anyio_1706220167567/work\r\n",
      "appdirs==1.4.4\r\n",
      "archspec @ file:///croot/archspec_1709217642129/work\r\n",
      "argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work\r\n",
      "argon2-cffi-bindings @ file:///work/ci_py311/argon2-cffi-bindings_1676823553406/work\r\n",
      "arrow @ file:///work/ci_py311/arrow_1677696236099/work\r\n",
      "astroid @ file:///work/ci_py311/astroid_1676920975848/work\r\n",
      "astropy @ file:///croot/astropy_1697468907928/work\r\n",
      "asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\r\n",
      "async-lru @ file:///croot/async-lru_1699554519285/work\r\n",
      "atomicwrites==1.4.0\r\n",
      "attrs @ file:///croot/attrs_1695717823297/work\r\n",
      "Automat @ file:///tmp/build/80754af9/automat_1600298431173/work\r\n",
      "autopep8 @ file:///opt/conda/conda-bld/autopep8_1650463822033/work\r\n",
      "Babel @ file:///work/ci_py311/babel_1676825020543/work\r\n",
      "backports.functools-lru-cache @ file:///tmp/build/80754af9/backports.functools_lru_cache_1618170165463/work\r\n",
      "backports.tempfile @ file:///home/linux1/recipes/ci/backports.tempfile_1610991236607/work\r\n",
      "backports.weakref==1.0.post1\r\n",
      "bcrypt @ file:///work/ci_py311/bcrypt_1676825144644/work\r\n",
      "beautifulsoup4 @ file:///croot/beautifulsoup4-split_1681493039619/work\r\n",
      "binaryornot @ file:///tmp/build/80754af9/binaryornot_1617751525010/work\r\n",
      "bitsandbytes==0.43.1\r\n",
      "black @ file:///croot/black_1701096792414/work\r\n",
      "bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work\r\n",
      "blinker @ file:///croot/blinker_1696539051175/work\r\n",
      "bokeh @ file:///croot/bokeh_1706912149278/work\r\n",
      "boltons @ file:///work/ci_py311/boltons_1677685195580/work\r\n",
      "botocore @ file:///croot/botocore_1701286451219/work\r\n",
      "Bottleneck @ file:///croot/bottleneck_1707864210935/work\r\n",
      "Brotli @ file:///work/ci_py311/brotli-split_1676830125088/work\r\n",
      "cachetools @ file:///tmp/build/80754af9/cachetools_1619597386817/work\r\n",
      "certifi @ file:///croot/certifi_1707229174982/work/certifi\r\n",
      "cffi @ file:///croot/cffi_1700254295673/work\r\n",
      "chardet @ file:///work/ci_py311/chardet_1676830276092/work\r\n",
      "charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work\r\n",
      "click @ file:///croot/click_1698129812380/work\r\n",
      "cloudpickle @ file:///croot/cloudpickle_1683040006038/work\r\n",
      "clyent==1.2.2\r\n",
      "colorama @ file:///work/ci_py311/colorama_1676827038675/work\r\n",
      "colorcet @ file:///work/ci_py311/colorcet_1676839173519/work\r\n",
      "comm @ file:///work/ci_py311/comm_1677709131612/work\r\n",
      "conda @ file:///croot/conda_1714403036266/work\r\n",
      "conda-build @ file:///croot/conda-build_1708025865815/work\r\n",
      "conda-content-trust @ file:///croot/conda-content-trust_1693490622020/work\r\n",
      "conda-libmamba-solver @ file:///croot/conda-libmamba-solver_1706733287605/work/src\r\n",
      "conda-pack @ file:///tmp/build/80754af9/conda-pack_1611163042455/work\r\n",
      "conda-package-handling @ file:///croot/conda-package-handling_1690999929514/work\r\n",
      "conda-repo-cli==1.0.75\r\n",
      "conda-token @ file:///Users/paulyim/miniconda3/envs/c3i/conda-bld/conda-token_1662660369760/work\r\n",
      "conda-verify==3.4.2\r\n",
      "conda_index @ file:///croot/conda-index_1706633791028/work\r\n",
      "conda_package_streaming @ file:///croot/conda-package-streaming_1690987966409/work\r\n",
      "constantly @ file:///croot/constantly_1703165600746/work\r\n",
      "contourpy @ file:///croot/contourpy_1700583582875/work\r\n",
      "cookiecutter @ file:///croot/cookiecutter_1700676941334/work\r\n",
      "cryptography @ file:///croot/cryptography_1707523700518/work\r\n",
      "cssselect @ file:///croot/cssselect_1707339882883/work\r\n",
      "cycler @ file:///tmp/build/80754af9/cycler_1637851556182/work\r\n",
      "cytoolz @ file:///croot/cytoolz_1701723583781/work\r\n",
      "dask @ file:///croot/dask-core_1701396095060/work\r\n",
      "datasets==2.19.0\r\n",
      "datashader @ file:///croot/datashader_1699542882288/work\r\n",
      "debugpy @ file:///croot/debugpy_1690905042057/work\r\n",
      "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\r\n",
      "defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work\r\n",
      "diff-match-patch @ file:///Users/ktietz/demo/mc3/conda-bld/diff-match-patch_1630511840874/work\r\n",
      "dill==0.3.8\r\n",
      "distributed @ file:///croot/distributed_1701398021707/work\r\n",
      "distro @ file:///croot/distro_1701455004953/work\r\n",
      "docstring-to-markdown @ file:///work/ci_py311/docstring-to-markdown_1676851973684/work\r\n",
      "docstring_parser==0.16\r\n",
      "docutils @ file:///work/ci_py311/docutils_1676822773036/work\r\n",
      "entrypoints @ file:///work/ci_py311/entrypoints_1676823319002/work\r\n",
      "et-xmlfile==1.1.0\r\n",
      "evaluate==0.4.2\r\n",
      "executing @ file:///opt/conda/conda-bld/executing_1646925071911/work\r\n",
      "fastjsonschema @ file:///work/ci_py311_2/python-fastjsonschema_1679340124475/work\r\n",
      "filelock @ file:///croot/filelock_1700591183607/work\r\n",
      "flake8 @ file:///work/ci_py311/flake8_1677709235205/work\r\n",
      "Flask @ file:///croot/flask_1702980023242/work\r\n",
      "fonttools==4.25.0\r\n",
      "frozenlist @ file:///croot/frozenlist_1698702560391/work\r\n",
      "fsspec @ file:///croot/fsspec_1701286474621/work\r\n",
      "future @ file:///work/ci_py311_2/future_1679335928186/work\r\n",
      "gensim @ file:///work/ci_py311/gensim_1677033391129/work\r\n",
      "gitdb @ file:///tmp/build/80754af9/gitdb_1617117951232/work\r\n",
      "GitPython @ file:///croot/gitpython_1696936983078/work\r\n",
      "gmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work\r\n",
      "greenlet @ file:///croot/greenlet_1702059959679/work\r\n",
      "grpcio==1.64.0\r\n",
      "h11 @ file:///croot/h11_1706652277403/work\r\n",
      "h5py @ file:///croot/h5py_1691589708553/work\r\n",
      "HeapDict @ file:///Users/ktietz/demo/mc3/conda-bld/heapdict_1630598515714/work\r\n",
      "holoviews @ file:///croot/holoviews_1707836454244/work\r\n",
      "httpcore @ file:///croot/httpcore_1706728464539/work\r\n",
      "httpx @ file:///croot/httpx_1706887096329/work\r\n",
      "huggingface-hub==0.22.2\r\n",
      "hvplot @ file:///croot/hvplot_1706712387811/work\r\n",
      "hyperlink @ file:///tmp/build/80754af9/hyperlink_1610130746837/work\r\n",
      "idna @ file:///work/ci_py311/idna_1676822698822/work\r\n",
      "imagecodecs @ file:///croot/imagecodecs_1695064943445/work\r\n",
      "imageio @ file:///croot/imageio_1707247282708/work\r\n",
      "imagesize @ file:///work/ci_py311/imagesize_1676830829500/work\r\n",
      "imbalanced-learn @ file:///croot/imbalanced-learn_1700648238098/work\r\n",
      "importlib-metadata @ file:///croot/importlib_metadata-suite_1704813515092/work\r\n",
      "incremental @ file:///croot/incremental_1708639938299/work\r\n",
      "inflection==0.5.1\r\n",
      "iniconfig @ file:///home/linux1/recipes/ci/iniconfig_1610983019677/work\r\n",
      "inquirerpy==0.3.4\r\n",
      "intake @ file:///work/ci_py311_2/intake_1679336472739/work\r\n",
      "intervaltree @ file:///Users/ktietz/demo/mc3/conda-bld/intervaltree_1630511889664/work\r\n",
      "ipykernel @ file:///croot/ipykernel_1705933831282/work\r\n",
      "ipython @ file:///croot/ipython_1704833016303/work\r\n",
      "ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work\r\n",
      "ipywidgets @ file:///croot/ipywidgets_1701289330913/work\r\n",
      "isort @ file:///tmp/build/80754af9/isort_1628603791788/work\r\n",
      "itemadapter @ file:///tmp/build/80754af9/itemadapter_1626442940632/work\r\n",
      "itemloaders @ file:///croot/itemloaders_1708639918324/work\r\n",
      "itsdangerous @ file:///tmp/build/80754af9/itsdangerous_1621432558163/work\r\n",
      "jaraco.classes @ file:///tmp/build/80754af9/jaraco.classes_1620983179379/work\r\n",
      "jedi @ file:///work/ci_py311_2/jedi_1679336495545/work\r\n",
      "jeepney @ file:///tmp/build/80754af9/jeepney_1627537048313/work\r\n",
      "jellyfish @ file:///croot/jellyfish_1695193535278/work\r\n",
      "Jinja2 @ file:///croot/jinja2_1706733616596/work\r\n",
      "jmespath @ file:///croot/jmespath_1700144569655/work\r\n",
      "joblib @ file:///croot/joblib_1685113087166/work\r\n",
      "json5 @ file:///tmp/build/80754af9/json5_1624432770122/work\r\n",
      "jsonpatch @ file:///tmp/build/80754af9/jsonpatch_1615747632069/work\r\n",
      "jsonpointer==2.1\r\n",
      "jsonschema @ file:///croot/jsonschema_1699041609003/work\r\n",
      "jsonschema-specifications @ file:///croot/jsonschema-specifications_1699032386549/work\r\n",
      "jupyter @ file:///croot/jupyter_1707947101020/work\r\n",
      "jupyter-console @ file:///croot/jupyter_console_1679999630278/work\r\n",
      "jupyter-events @ file:///croot/jupyter_events_1699282461638/work\r\n",
      "jupyter-lsp @ file:///croot/jupyter-lsp-meta_1699978238815/work\r\n",
      "jupyter-ydoc @ file:///croot/jupyter_ydoc_1683747223142/work\r\n",
      "jupyter_client @ file:///work/ci_py311/jupyter_client_1676823491351/work\r\n",
      "jupyter_core @ file:///croot/jupyter_core_1698937308754/work\r\n",
      "jupyter_server @ file:///croot/jupyter_server_1699466442171/work\r\n",
      "jupyter_server_fileid @ file:///croot/jupyter_server_fileid_1684273577568/work\r\n",
      "jupyter_server_terminals @ file:///croot/jupyter_server_terminals_1686870725608/work\r\n",
      "jupyter_server_ydoc @ file:///croot/jupyter_server_ydoc_1686767404829/work\r\n",
      "jupyterlab @ file:///croot/jupyterlab_1708029878135/work\r\n",
      "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\r\n",
      "jupyterlab-widgets @ file:///croot/jupyterlab_widgets_1700168618520/work\r\n",
      "jupyterlab_server @ file:///croot/jupyterlab_server_1699555425460/work\r\n",
      "keyring @ file:///croot/keyring_1678999217139/work\r\n",
      "kiwisolver @ file:///work/ci_py311/kiwisolver_1676827230232/work\r\n",
      "lazy-object-proxy @ file:///work/ci_py311/lazy-object-proxy_1676827255418/work\r\n",
      "lazy_loader @ file:///croot/lazy_loader_1695850097191/work\r\n",
      "lckr_jupyterlab_variableinspector @ file:///croot/jupyterlab-variableinspector_1701096569343/work\r\n",
      "libarchive-c @ file:///tmp/build/80754af9/python-libarchive-c_1617780486945/work\r\n",
      "libmambapy @ file:///croot/mamba-split_1704219408234/work/libmambapy\r\n",
      "linkify-it-py @ file:///work/ci_py311/linkify-it-py_1676837069144/work\r\n",
      "llvmlite @ file:///croot/llvmlite_1706910704562/work\r\n",
      "lmdb @ file:///croot/python-lmdb_1682522346377/work\r\n",
      "locket @ file:///work/ci_py311/locket_1676827274546/work\r\n",
      "lxml @ file:///croot/lxml_1695058164555/work\r\n",
      "lz4 @ file:///croot/lz4_1686057876374/work\r\n",
      "Markdown @ file:///work/ci_py311/markdown_1676837083112/work\r\n",
      "markdown-it-py @ file:///croot/markdown-it-py_1684279902645/work\r\n",
      "MarkupSafe @ file:///croot/markupsafe_1704205993651/work\r\n",
      "matplotlib @ file:///croot/matplotlib-suite_1698692105134/work\r\n",
      "matplotlib-inline @ file:///work/ci_py311/matplotlib-inline_1676823841154/work\r\n",
      "mccabe @ file:///opt/conda/conda-bld/mccabe_1644221741721/work\r\n",
      "mdit-py-plugins @ file:///work/ci_py311/mdit-py-plugins_1676837111662/work\r\n",
      "mdurl @ file:///work/ci_py311/mdurl_1676827289376/work\r\n",
      "menuinst @ file:///croot/menuinst_1706732933928/work\r\n",
      "mistune @ file:///work/ci_py311/mistune_1676823683049/work\r\n",
      "mkl-fft @ file:///croot/mkl_fft_1695058164594/work\r\n",
      "mkl-random @ file:///croot/mkl_random_1695059800811/work\r\n",
      "mkl-service==2.4.0\r\n",
      "more-itertools @ file:///croot/more-itertools_1700662129964/work\r\n",
      "mpmath @ file:///croot/mpmath_1690848262763/work\r\n",
      "msgpack @ file:///work/ci_py311/msgpack-python_1676823037805/work\r\n",
      "multidict @ file:///croot/multidict_1701096859099/work\r\n",
      "multipledispatch @ file:///work/ci_py311/multipledispatch_1676841220684/work\r\n",
      "multiprocess==0.70.16\r\n",
      "munkres==1.1.4\r\n",
      "mypy @ file:///croot/mypy-split_1708366513367/work\r\n",
      "mypy-extensions @ file:///croot/mypy_extensions_1695130926492/work\r\n",
      "navigator-updater @ file:///croot/navigator-updater_1695210188412/work\r\n",
      "nbclassic @ file:///croot/nbclassic_1699542793266/work\r\n",
      "nbclient @ file:///croot/nbclient_1698934205032/work\r\n",
      "nbconvert @ file:///croot/nbconvert_1699022732553/work\r\n",
      "nbformat @ file:///croot/nbformat_1694616755618/work\r\n",
      "nest-asyncio @ file:///croot/nest-asyncio_1708532673751/work\r\n",
      "networkx @ file:///croot/networkx_1690561992265/work\r\n",
      "nltk @ file:///croot/nltk_1688114146592/work\r\n",
      "notebook @ file:///croot/notebook_1690984815942/work\r\n",
      "notebook_shim @ file:///croot/notebook-shim_1699455894279/work\r\n",
      "numba @ file:///croot/numba_1707085079500/work\r\n",
      "numexpr @ file:///croot/numexpr_1696515281613/work\r\n",
      "numpy @ file:///croot/numpy_and_numpy_base_1708638617955/work/dist/numpy-1.26.4-cp311-cp311-linux_x86_64.whl#sha256=5f96f274d410a1682519282ae769c877d32fdbf171aa8badec7bf5e1d3a1748a\r\n",
      "numpydoc @ file:///work/ci_py311/numpydoc_1676845056742/work\r\n",
      "nvidia-cublas-cu12==12.1.3.1\r\n",
      "nvidia-cuda-cupti-cu12==12.1.105\r\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\r\n",
      "nvidia-cuda-runtime-cu12==12.1.105\r\n",
      "nvidia-cudnn-cu12==8.9.2.26\r\n",
      "nvidia-cufft-cu12==11.0.2.54\r\n",
      "nvidia-curand-cu12==10.3.2.106\r\n",
      "nvidia-cusolver-cu12==11.4.5.107\r\n",
      "nvidia-cusparse-cu12==12.1.0.106\r\n",
      "nvidia-nccl-cu12==2.20.5\r\n",
      "nvidia-nvjitlink-cu12==12.4.127\r\n",
      "nvidia-nvtx-cu12==12.1.105\r\n",
      "openpyxl==3.0.10\r\n",
      "overrides @ file:///croot/overrides_1699371140756/work\r\n",
      "packaging @ file:///croot/packaging_1693575174725/work\r\n",
      "pandas @ file:///croot/pandas_1702317985682/work/dist/pandas-2.1.4-cp311-cp311-linux_x86_64.whl#sha256=a15c481f210e34ff91dac4944a5f8f0fe38ff2c3afa7c45ea621ff460d6f9b57\r\n",
      "pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work\r\n",
      "panel @ file:///croot/panel_1706539561184/work\r\n",
      "param @ file:///croot/param_1705937765746/work\r\n",
      "parsel @ file:///croot/parsel_1707503445438/work\r\n",
      "parso @ file:///opt/conda/conda-bld/parso_1641458642106/work\r\n",
      "partd @ file:///croot/partd_1698702562572/work\r\n",
      "pathlib @ file:///Users/ktietz/demo/mc3/conda-bld/pathlib_1629713961906/work\r\n",
      "pathspec @ file:///work/ci_py311_2/pathspec_1679337288229/work\r\n",
      "patsy==0.5.3\r\n",
      "peft==0.10.0\r\n",
      "pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\r\n",
      "pfzy==0.3.4\r\n",
      "pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\r\n",
      "pillow @ file:///croot/pillow_1707233021655/work\r\n",
      "pkce @ file:///croot/pkce_1690384816590/work\r\n",
      "pkginfo @ file:///croot/pkginfo_1679431160147/work\r\n",
      "platformdirs @ file:///croot/platformdirs_1692205439124/work\r\n",
      "plotly @ file:///work/ci_py311/plotly_1676841625489/work\r\n",
      "pluggy @ file:///work/ci_py311/pluggy_1676822818071/work\r\n",
      "ply==3.11\r\n",
      "prometheus-client @ file:///work/ci_py311_2/prometheus_client_1679340520168/work\r\n",
      "prompt-toolkit @ file:///croot/prompt-toolkit_1704404351921/work\r\n",
      "Protego @ file:///tmp/build/80754af9/protego_1598657180827/work\r\n",
      "protobuf==3.20.3\r\n",
      "psutil @ file:///work/ci_py311_2/psutil_1679337388738/work\r\n",
      "ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\n",
      "pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\r\n",
      "py-cpuinfo @ file:///croot/py-cpuinfo_1698068081650/work\r\n",
      "pyarrow @ file:///croot/pyarrow_1707330824290/work/python\r\n",
      "pyarrow-hotfix==0.6\r\n",
      "pyasn1 @ file:///Users/ktietz/demo/mc3/conda-bld/pyasn1_1629708007385/work\r\n",
      "pyasn1-modules==0.2.8\r\n",
      "pycodestyle @ file:///work/ci_py311/pycodestyle_1677708783451/work\r\n",
      "pycosat @ file:///croot/pycosat_1696536503704/work\r\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\r\n",
      "pyct @ file:///work/ci_py311/pyct_1676838544646/work\r\n",
      "pycurl @ file:///croot/pycurl_1686662440405/work\r\n",
      "pydantic @ file:///croot/pydantic_1695798841041/work\r\n",
      "pydeck @ file:///croot/pydeck_1706194064552/work\r\n",
      "PyDispatcher==2.0.5\r\n",
      "pydocstyle @ file:///work/ci_py311/pydocstyle_1677708708066/work\r\n",
      "pyerfa @ file:///work/ci_py311/pyerfa_1676838574038/work\r\n",
      "pyflakes @ file:///work/ci_py311/pyflakes_1677708650266/work\r\n",
      "Pygments @ file:///croot/pygments_1684279966437/work\r\n",
      "PyJWT @ file:///work/ci_py311/pyjwt_1676827385359/work\r\n",
      "pylint @ file:///work/ci_py311/pylint_1676920998643/work\r\n",
      "pylint-venv @ file:///work/ci_py311/pylint-venv_1677706395472/work\r\n",
      "pyls-spyder==0.4.0\r\n",
      "pyodbc @ file:///croot/pyodbc_1705431351638/work\r\n",
      "pyOpenSSL @ file:///croot/pyopenssl_1708380408460/work\r\n",
      "pyparsing @ file:///work/ci_py311/pyparsing_1677811559502/work\r\n",
      "PyQt5==5.15.10\r\n",
      "PyQt5-sip @ file:///croot/pyqt-split_1698769088074/work/pyqt_sip\r\n",
      "PyQtWebEngine==5.15.6\r\n",
      "PySocks @ file:///work/ci_py311/pysocks_1676822712504/work\r\n",
      "pytest @ file:///croot/pytest_1690474690005/work\r\n",
      "python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\r\n",
      "python-dotenv @ file:///work/ci_py311/python-dotenv_1676842320650/work\r\n",
      "python-json-logger @ file:///croot/python-json-logger_1683823803357/work\r\n",
      "python-lsp-black @ file:///work/ci_py311/python-lsp-black_1676845562358/work\r\n",
      "python-lsp-jsonrpc==1.0.0\r\n",
      "python-lsp-server @ file:///croot/python-lsp-server_1681930392028/work\r\n",
      "python-slugify @ file:///tmp/build/80754af9/python-slugify_1620405669636/work\r\n",
      "python-snappy @ file:///work/ci_py311/python-snappy_1676842365339/work\r\n",
      "pytoolconfig @ file:///croot/pytoolconfig_1701728692402/work\r\n",
      "pytz @ file:///croot/pytz_1695131579487/work\r\n",
      "pyviz-comms @ file:///croot/pyviz_comms_1685030693726/work\r\n",
      "pywavelets @ file:///croot/pywavelets_1705049820073/work\r\n",
      "pyxdg @ file:///tmp/build/80754af9/pyxdg_1603822279816/work\r\n",
      "PyYAML @ file:///croot/pyyaml_1698096049011/work\r\n",
      "pyzmq @ file:///croot/pyzmq_1709318311506/work\r\n",
      "QDarkStyle @ file:///tmp/build/80754af9/qdarkstyle_1617386714626/work\r\n",
      "qstylizer @ file:///work/ci_py311/qstylizer_1677706154568/work/dist/qstylizer-0.2.2-py2.py3-none-any.whl\r\n",
      "QtAwesome @ file:///work/ci_py311/qtawesome_1677705159328/work\r\n",
      "qtconsole @ file:///croot/qtconsole_1681394213385/work\r\n",
      "QtPy @ file:///croot/qtpy_1700144840038/work\r\n",
      "queuelib @ file:///croot/queuelib_1696950067631/work\r\n",
      "referencing @ file:///croot/referencing_1699012038513/work\r\n",
      "regex @ file:///croot/regex_1696515298636/work\r\n",
      "requests @ file:///croot/requests_1707355572290/work\r\n",
      "requests-file @ file:///Users/ktietz/demo/mc3/conda-bld/requests-file_1629455781986/work\r\n",
      "requests-toolbelt @ file:///croot/requests-toolbelt_1690874004362/work\r\n",
      "rfc3339-validator @ file:///croot/rfc3339-validator_1683077044675/work\r\n",
      "rfc3986-validator @ file:///croot/rfc3986-validator_1683058983515/work\r\n",
      "rich @ file:///croot/rich_1684282154404/work\r\n",
      "rope @ file:///work/ci_py311/rope_1677708536193/work\r\n",
      "rouge-score==0.1.2\r\n",
      "rpds-py @ file:///croot/rpds-py_1698945930462/work\r\n",
      "Rtree @ file:///work/ci_py311/rtree_1676845693189/work\r\n",
      "ruamel-yaml-conda @ file:///work/ci_py311/ruamel_yaml_1676845707897/work\r\n",
      "ruamel.yaml @ file:///work/ci_py311/ruamel.yaml_1676838772170/work\r\n",
      "s3fs @ file:///croot/s3fs_1701294169021/work\r\n",
      "safetensors==0.4.3\r\n",
      "scikit-image @ file:///croot/scikit-image_1707346116243/work\r\n",
      "scikit-learn @ file:///croot/scikit-learn_1684954695550/work\r\n",
      "scipy @ file:///croot/scipy_1701295040508/work/dist/scipy-1.11.4-cp311-cp311-linux_x86_64.whl#sha256=4a1942ba48a330f141b1056df960d77f9be4cee3e2d999d754e791da201edffd\r\n",
      "Scrapy @ file:///work/ci_py311/scrapy_1677770267574/work\r\n",
      "seaborn @ file:///work/ci_py311/seaborn_1676845747354/work\r\n",
      "SecretStorage @ file:///work/ci_py311_2/secretstorage_1679339060489/work\r\n",
      "semver @ file:///tmp/build/80754af9/semver_1603822362442/work\r\n",
      "Send2Trash @ file:///croot/send2trash_1699371139552/work\r\n",
      "service-identity @ file:///Users/ktietz/demo/mc3/conda-bld/service_identity_1629460757137/work\r\n",
      "shtab==1.7.1\r\n",
      "sip @ file:///croot/sip_1698675935381/work\r\n",
      "six @ file:///tmp/build/80754af9/six_1644875935023/work\r\n",
      "smart-open @ file:///work/ci_py311/smart_open_1676842848397/work\r\n",
      "smmap @ file:///tmp/build/80754af9/smmap_1611694433573/work\r\n",
      "sniffio @ file:///croot/sniffio_1705431295498/work\r\n",
      "snowballstemmer @ file:///tmp/build/80754af9/snowballstemmer_1637937080595/work\r\n",
      "sortedcontainers @ file:///tmp/build/80754af9/sortedcontainers_1623949099177/work\r\n",
      "soupsieve @ file:///croot/soupsieve_1696347547217/work\r\n",
      "Sphinx @ file:///work/ci_py311/sphinx_1676842864059/work\r\n",
      "sphinxcontrib-applehelp @ file:///home/ktietz/src/ci/sphinxcontrib-applehelp_1611920841464/work\r\n",
      "sphinxcontrib-devhelp @ file:///home/ktietz/src/ci/sphinxcontrib-devhelp_1611920923094/work\r\n",
      "sphinxcontrib-htmlhelp @ file:///tmp/build/80754af9/sphinxcontrib-htmlhelp_1623945626792/work\r\n",
      "sphinxcontrib-jsmath @ file:///home/ktietz/src/ci/sphinxcontrib-jsmath_1611920942228/work\r\n",
      "sphinxcontrib-qthelp @ file:///home/ktietz/src/ci/sphinxcontrib-qthelp_1611921055322/work\r\n",
      "sphinxcontrib-serializinghtml @ file:///tmp/build/80754af9/sphinxcontrib-serializinghtml_1624451540180/work\r\n",
      "spyder @ file:///croot/spyder_1681934064788/work\r\n",
      "spyder-kernels @ file:///croot/spyder-kernels_1691599531749/work\r\n",
      "SQLAlchemy @ file:///croot/sqlalchemy_1705089115293/work\r\n",
      "stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\r\n",
      "statsmodels @ file:///croot/statsmodels_1689937266057/work\r\n",
      "streamlit @ file:///croot/streamlit_1706200479775/work\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sympy @ file:///croot/sympy_1701397643339/work\n",
      "tables @ file:///croot/pytables_1705614842881/work\n",
      "tabulate @ file:///croot/tabulate_1701354810597/work\n",
      "tblib @ file:///Users/ktietz/demo/mc3/conda-bld/tblib_1629402031467/work\n",
      "tenacity @ file:///croot/tenacity_1682972284834/work\n",
      "tensorboard==2.16.2\n",
      "tensorboard-data-server==0.7.2\n",
      "terminado @ file:///work/ci_py311/terminado_1677696151350/work\n",
      "text-unidecode @ file:///Users/ktietz/demo/mc3/conda-bld/text-unidecode_1629401354553/work\n",
      "textdistance @ file:///tmp/build/80754af9/textdistance_1612461398012/work\n",
      "threadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\n",
      "three-merge @ file:///tmp/build/80754af9/three-merge_1607553261110/work\n",
      "tifffile @ file:///croot/tifffile_1695107451082/work\n",
      "tinycss2 @ file:///work/ci_py311/tinycss2_1676823757641/work\n",
      "tldextract @ file:///opt/conda/conda-bld/tldextract_1646638314385/work\n",
      "tokenizers==0.19.1\n",
      "toml @ file:///tmp/build/80754af9/toml_1616166611790/work\n",
      "tomlkit @ file:///work/ci_py311/tomlkit_1676823218885/work\n",
      "toolz @ file:///work/ci_py311/toolz_1676827522705/work\n",
      "torch==2.3.0\n",
      "tornado @ file:///croot/tornado_1696936946304/work\n",
      "tqdm @ file:///croot/tqdm_1679561862951/work\n",
      "traitlets @ file:///work/ci_py311/traitlets_1676823305040/work\n",
      "transformers==4.40.1\n",
      "triton==2.3.0\n",
      "trl==0.8.6\n",
      "truststore @ file:///croot/truststore_1695244293384/work\n",
      "Twisted @ file:///croot/twisted_1708702809815/work\n",
      "typing_extensions @ file:///croot/typing_extensions_1705599297034/work\n",
      "tyro==0.8.3\n",
      "tzdata @ file:///croot/python-tzdata_1690578112552/work\n",
      "tzlocal @ file:///work/ci_py311/tzlocal_1676842973332/work\n",
      "uc-micro-py @ file:///work/ci_py311/uc-micro-py_1676828889155/work\n",
      "ujson @ file:///work/ci_py311/ujson_1676828903327/work\n",
      "Unidecode @ file:///tmp/build/80754af9/unidecode_1614712377438/work\n",
      "urllib3 @ file:///croot/urllib3_1707349237698/work\n",
      "validators @ file:///tmp/build/80754af9/validators_1612286467315/work\n",
      "w3lib @ file:///croot/w3lib_1708639924738/work\n",
      "watchdog @ file:///work/ci_py311/watchdog_1676846191736/work\n",
      "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\n",
      "webencodings==0.5.1\n",
      "websocket-client @ file:///work/ci_py311/websocket-client_1676824890004/work\n",
      "Werkzeug @ file:///croot/werkzeug_1679489717957/work\n",
      "whatthepatch @ file:///work/ci_py311/whatthepatch_1677708379946/work\n",
      "widgetsnbextension @ file:///croot/widgetsnbextension_1701273613663/work\n",
      "wrapt @ file:///work/ci_py311/wrapt_1676827586170/work\n",
      "wurlitzer @ file:///work/ci_py311/wurlitzer_1676843053614/work\n",
      "xarray @ file:///croot/xarray_1689041471350/work\n",
      "xxhash==3.4.1\n",
      "xyzservices @ file:///work/ci_py311/xyzservices_1676828923127/work\n",
      "y-py @ file:///croot/y-py_1683555143488/work\n",
      "yapf @ file:///tmp/build/80754af9/yapf_1615749224965/work\n",
      "yarl @ file:///croot/yarl_1701105127787/work\n",
      "ypy-websocket @ file:///croot/ypy-websocket_1684171737040/work\n",
      "zict @ file:///croot/zict_1695832839030/work\n",
      "zipp @ file:///croot/zipp_1704206909481/work\n",
      "zope.interface @ file:///work/ci_py311/zope.interface_1676905896080/work\n",
      "zstandard @ file:///work/ci_py311_2/zstandard_1679339489613/work\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b56de47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
